{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Panel Methods ðŸš¢ \n",
    "\n",
    "A panel method is a numerical approach to constructing potential flows around engineering shapes such as an offshore platform, sail or ship hull. Panel methods are typically fast enough for design iteration on 3D geometries, but they come with modelling and numerical errors that need to be quantified. \n",
    "\n",
    "A panel method is a type of Boundary Element Methods (BEM), which have a rich and somewhat intimidating mathematical background. However, the mathematics and numerics of panels methods are very straightforward and give a good introduction to numerical analysis as well as being useful in application. \n",
    "\n",
    "## Method overview\n",
    "\n",
    "The basic steps of a potential flow panel method can be summarized as:\n",
    " - The boundaries of the fluid domain are given as an input and covered in small panels, each with their own influence potential $\\phi$.\n",
    " - The total potential $\\varphi$ defined as the superposition of each panel's $\\phi$ scaled by an unknown strength $q$.\n",
    " - The strengths are determined such that the flow boundary conditions, such as the normal velocity condition $U_n=\\frac{\\partial\\varphi}{\\partial n}$, are satisfied on every panel.\n",
    " - With the potential now defined, any quantity of interest can be measured, such as the surface pressure $p$ using $\\vec u=\\vec\\nabla\\varphi$ and the Bernoulli equation.\n",
    "\n",
    "We will developing a programme to follow these steps, and will raise (and address) a few important numerical questions in the process:\n",
    " 1. _How can we calculate the influence of each panel $\\phi$?_ **Gaussian quadratures.**\n",
    " 2. _How should we compute the derivatives of $\\phi$ and other functions?_ **Automatic differentiation.**\n",
    " 3. _How can we find the optimal $q$ for each panel?_ **Set-up and solve a linear system.**\n",
    " 4. _How should we determine if a method is working?_ **Convergence and validation tests.** \n",
    "\n",
    " We'll answer the first two questions in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential of a source panel ðŸš°\n",
    "\n",
    "The velocity potential of a panel per unit strength (called the _influence_) is defined as\n",
    "\n",
    "$$ \\phi(\\vec x) = \\int\\int G(\\vec x,\\vec S(\\xi,\\zeta))\\ d\\xi d\\zeta $$\n",
    "\n",
    "where $S$ is the surface of the panel, described by coordinates $\\xi$ and $\\zeta$, and $G$ is the Green Function, which needs to be a solution of the laplace equations $\\nabla^2 G=0$. For every point $\\vec x$ where you want the potential, you must evaluate this double integral over the surface coordinates.\n",
    "\n",
    "The functions inside this integral are known: the geometry $S$ is _the_ input (a portion of a sphere, a bit of the hull defined by a spline, etc), and we will choose $G$ to be the source potential\n",
    "\n",
    "$$ G(\\vec x, \\vec c) = \\frac{-1}{|\\vec x-\\vec c|}$$\n",
    "\n",
    "Despite this, the integral for $\\phi$ is not analytically solvable, except for special-case $S$ shapes. This is in stark contrast to derivatives! If we had $\\phi=\\frac{\\partial}{\\partial \\xi} G(x,S(\\xi,\\zeta))$ we would have no problem carrying out this derivative using the chain rule, even for complex shapes. Integrals don't have an equivalent rule that always works! Our first question is therefore:\n",
    "\n",
    " 1. _How can we calculate the influence of each panel $\\phi$?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical integration quadratures\n",
    "\n",
    "While we can't calculate the influence analytically, **quadratures** are simple and effective methods to numerically approximate integrals. Consider the integral\n",
    "\n",
    "$$ F = \\int_{-h/2}^{h/2} f(x) dx $$\n",
    "\n",
    "where $h$ is a small interval. You're already familiar with many example quadratures we can use to estimate this integral:\n",
    " - mid-point rule: $F \\approx h f(0)$\n",
    " - trapezoid rule: $F \\approx \\frac h2 [f(-h/2)+f(h/2)]$\n",
    " - Simpson's rule: $F \\approx \\frac h6 [f(-h/2)+4f(0)+f(h/2)]$\n",
    "\n",
    "These algorithms are all simple but they require 1,2 and 3 function evaluations, respectively. How much more accuracy are we getting for the increased amount of work? We can determine this by expressing $f$ in terms of it's Taylor series\n",
    "\n",
    "$$ f(x) = f_0+\\frac x2 f_0' + \\frac{x^2}6 f_0'' + \\frac{x^3}{12} f_0''' + \\ldots $$\n",
    "\n",
    "where subscript 0 denotes evaluation at $x=0$ and each tick $'$ indicates a derivative. Substitution into the integral and algebraic manipulation gives:\n",
    " - mid-point: $F = hf_0 + \\frac 1{24} h^3 f_0'' + O(h^4)$\n",
    " - trapezoid: $F = \\frac h2 [f(-h/2)+f(h/2)] -\\frac 1{12}h^3 f_0''+O(h^4)$\n",
    " - Simpson's: $F = \\frac h6 [f(-h/2)+4f(0)+f(h/2)] + O(h^4)$\n",
    "\n",
    "where $O(h^4)$ means all the following terms are proportional to $h$ to the power of 4 or greater. Since the quadrature neglected these additional terms, they have a well-defined _truncation error_.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b> Type 3: Numerical Truncation Error </b>\n",
    "\n",
    "Errors due to truncating an infinite series at some power of the step length $h$\n",
    "</div>\n",
    "\n",
    "Unlike system description errors or modelling errors, numerical truncation errors can be well estimated and controlled without access to the \"true\" result. We can see that the simple midpoint rule is quite accurate: **as long as the function is smooth such that the derivatives don't blow up, a small value of $h$ will make $h^3 f''$ negligible**. Surprisingly, the trapezoid rule _doubles_ the error of the midpoint rule and doubles evaluations, so it's not a good choice.\n",
    "\n",
    "The midpoint rule applied to the influence potential integral gives:\n",
    "\n",
    "$$ \\phi(\\vec x) \\approx A G(\\vec x,\\vec c)=\\frac{-A}{|\\vec x-\\vec c|} $$\n",
    "\n",
    "where $A$ and $\\vec c$ are the area and centroid of the panel. Note that is just a point-source located at the panel centroid with $s=A$. This should raise some red flags because the whole point of using panels was to smooth out the singularity, and now it's back! \n",
    "\n",
    "_Will this approximation really be sufficiently accurate for our panel method?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Julia coding example\n",
    "\n",
    "Let's answer this question using an example: a 2D point source at the origin $G=\\frac 12 \\log(x^2)$ integrated on panels covering the x axis.\n",
    "\n",
    "âš ï¸ WARNING âš ï¸: This part of the course uses Julia, not Python or MATLAB. Julia has a bunch of advantages that help when writing a panel method. It's simple and flexible and [very fast](https://julialang.org/benchmarks/) at numerical computing!\n",
    "\n",
    "![Julia benchmarks](https://julialang.org/assets/images/benchmarks.svg)\n",
    "\n",
    "The syntax is similar to Python and MATLAB and here is a list of [note-worthy differences between Julia and other languages](https://web.mit.edu/julia_v0.6.2/julia/share/doc/julia/html/en/manual/noteworthy-differences.html) to help you make the switch. The code below is a good example of basic Julia syntax, and I've added extra comments to explain each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the functions we need\n",
    "### Look how easy this is in Julia! No more `def G(x): return stuff`\n",
    "G(x) = 0.5log(x^2)                 # 2D source at xâ‚€=0\n",
    "G_int(x) = 0.5x*log(x^2)-x         # indefinite integral\n",
    "midpoint(f,a,b) = (b-a)*f((a+b)/2) # Midpoint rule for any function `f`\n",
    "\n",
    "# Next let's plot the Green's function\n",
    "### Plots is the basic plotting package for Julia\n",
    "using Plots \n",
    "plot(range(-1,1,50),G,label=\"G\",ylims=(-1.5,0),xlabel=\"x\")\n",
    "\n",
    "# Split up the x-axis into panels\n",
    "### The range function and slicing is like Python\n",
    "### but adding vectors works automatically\n",
    "x = range(-1,1,10) # \"panels\" running along x-axis\n",
    "scatter!(x,zero,shape=:vline,c=:black,label=\"panels\")\n",
    "a = x[1:end-1]     # lower limits of each panel\n",
    "b = x[2:end]       # upper limits\n",
    "m = (a+b)/2        # panel midpoint\n",
    "\n",
    "# Finally, we can compare the exact and numeric panel integrals\n",
    "### The `f.(x)` syntax \"broadcasts\" the function over input vectors\n",
    "### similar to a list comprehension.\n",
    "exact = G_int.(b) - G_int.(a) # same as [G_int(aáµ¢)-G_int(báµ¢) for (aáµ¢,báµ¢) in zip(a,b)]\n",
    "numeric = midpoint.(G,a,b)    # same as [midpoint(G,aáµ¢,báµ¢) for (aáµ¢,báµ¢) in zip(a,b)]\n",
    "scatter!(m,exact,label=\"Exact integral\")\n",
    "scatter!(m,numeric,alpha=0.5,label=\"Midpoint rule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact integral and the midpoint rule results are directly on top of each other at the edges of the range. However, $G_0=-\\infty$ making the midpoint rule singular despite the fact that the true integral is well defined.\n",
    "\n",
    "So the midpoint rule is sufficient as long as we are not too close to the singularity, i.e. $|x|>>h$. However, we need a better approximation near 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian quadratures\n",
    "\n",
    "[Gaussian quadratures](https://en.wikipedia.org/wiki/Gaussian_quadrature) are family of simple but **very** accurate integration rules which are used in many engineering methods such as finite element methods. A Gaussian quadrature requires evaluating the function at $n$ special points $x_i$ (instead of simple fractions of $h$) and computing their sum with weights $w_i$.\n",
    "\n",
    " - Gauss quadrature rule: $F = \\int_{-1}^{1} f(x) dx \\approx \\sum_{i=1}^n w_i f(x_i)$\n",
    "\n",
    "The 1-point rule uses $x=[0],\\ w=[2]$ matching the midpoint rule. However, the error is proportional to $h^{2n+1}f^{(2n)}$, so every additional point scales the error down by $h^2$ for smooth functions! This is **much** better than the fractional-step methods like Trapezoid and Simpson's rule.\n",
    "\n",
    "![2-point Gauss quadrature](https://upload.wikimedia.org/wikipedia/commons/9/93/Comparison_Gaussquad_trapezoidal.svg)\n",
    "\n",
    "As illustrated in this figure, the 2-point quadrature uses $x=[\\frac{-1}{\\sqrt{3}},\\frac{1}{\\sqrt{3}}]$ with $w=[1,1]$ and exactly integrates any cubic (since $f^{(4)}=0$ for a cubic). \n",
    "\n",
    "Let's try this on our example problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Gauss-Legendre points and weights\n",
    "### `w'` is the transpose of the weight vector, \n",
    "### and `w'*v = wâ‚vâ‚+wâ‚‚vâ‚‚+...` is the inner product\n",
    "xgl,wgl = [-1/âˆš3,1/âˆš3],[1,1]\n",
    "quadgl(f;x=xgl,w=wgl) = w'*f.(x) # same as sum(wáµ¢*f(xáµ¢) for (xáµ¢,wáµ¢) in zip(x,w))\n",
    "\n",
    "# Convert the range from [-1,1] to [a,b]\n",
    "### This gives an example of how multi-line functions are defined\n",
    "### as well as in-place functions like `x->g(2x)`\n",
    "function quadgl_ab(f,a,b)\n",
    "    h,j = (b-a)/2,(a+b)/2 # spacing and center\n",
    "    h*quadgl(t->f(j+h*t))\n",
    "end\n",
    "\n",
    "# Apply to the example\n",
    "gauss = quadgl_ab.(G,a,b)\n",
    "plot(range(-1,1,50),G,label=\"G\",ylims=(-1.5,0),xlabel=\"x\")\n",
    "scatter!(x,zero,shape=:vline,c=:black,label=\"panels\")\n",
    "scatter!(m,exact,label=\"Exact integral\")\n",
    "scatter!(m,numeric,alpha=0.5,label=\"Midpoint rule\")\n",
    "scatter!(m,gauss,alpha=0.5,label=\"2-point Gauss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2-point Gaussian quadrature requires two function evaluations, but gives nearly perfect results for all  $x\\ne 0$. The estimate on the center panel is finite (yay!) and it's error is proportional to $h$. \n",
    "\n",
    "Based on this, our simple panel method will use the 1-point (midpoint) quadrature for all $|\\vec x-\\vec c|^2 \\gg A^2$, and a 2-point quadrature in both $\\xi$ and $\\zeta$ (requiring 2x2=4 function evaluations) otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity influence\n",
    "\n",
    "Now that the panel influence potential is defined, it's influence on the velocity is $\\vec \\nabla \\phi$. We will need to compute these velocities both in setting the boundary conditions and in evaluating the solution (once we have it), leading to our second numerical question and some optional solutions...\n",
    "\n",
    " 2. _How should we approximate these derivatives numerically?_\n",
    "  - Try to hand-calculate the derivatives and code them without messing up\n",
    "  - Use finite differences and accept surprisingly big numerical errors\n",
    "  - Let the computer determine the analytic derivatives for us\n",
    "\n",
    "The third option sounds magical at first, but the derivative rules are very simple algorithms like: \n",
    "\n",
    "$$ (f(g(x)))' = f'(g(x)) g'(x) $$\n",
    "\n",
    "Letting the computer apply these rules for you is called [automatic differentiation](https://www.ams.org/publicoutreach/feature-column/fc-2017-12) or AutoDiff. Julia *is* fast, but a huge reason to use it is that **all Julia code is differentiable**. \n",
    "\n",
    "Let's test out all three options on our 2D source example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ForwardDiff: derivative\n",
    "dG_hand(x) = 1/x # (0.5log(xÂ²))' = 0.5log'(xÂ²)*(xÂ²)' = 0.5/xÂ²*2x = 1/x\n",
    "dG_finite(x;e=eps()) = (G(x+e)-G(x-e))/2e ### eps() is the smallest floating point number\n",
    "dG_auto(x) = derivative(G,x) # Wow! Hard work!!\n",
    "plot(range(-1,1,50),dG_hand,xlabel=\"x\",label=\"By hand\",ylims=(-6,6))\n",
    "scatter!(range(-1,1,12),dG_finite,ls=:dashdot,label=\"FiniteDiff\")\n",
    "scatter!(range(-1,1,12),dG_auto,ls=:dash,alpha=0.5,label=\"AutoDiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The finite difference results are surprisingly bad! We've used the smallest step possible, but we have not converged to the analytic derivative produced by the other two methods. This is a second type of numerical error:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b> Type 4: Numerical Floating Point Error </b>\n",
    "\n",
    "Errors due to representing real numbers with a finite precision binary number\n",
    "</div>\n",
    "\n",
    "While a [double-precision number](https://en.wikipedia.org/wiki/Floating-point_arithmetic) (the Julia default) is typically fine, finite differences over small intervals become unstable due to rounding.\n",
    "\n",
    "In contrast, AutoDiff generates functions **for the analytic derivatives!** And doing so automatically avoids potential blunders in our hand calculation and bugs in our implementation. Clearly, we'll use AutoDiff in this solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook investigates the different numerical methods we can use to evalute the influence potential integral $\\phi$ and it's derivatives. We found\n",
    " - Truncation errors are proportional to the step size $h$ raised to a power.\n",
    " - Gaussian quadratures have smaller errors than fractional step methods.\n",
    " - More evaluation points are needed when the integrand has large derivatives.\n",
    " - Floating point errors are due to finite precision arithmetic.\n",
    " - Finite differences can exibit large floating point errors if $h\\sim \\epsilon$.\n",
    " - Automatic differentiation generates functions for the analytic derivative, avoiding this source of error as well as human error in hand calculations.\n",
    "\n",
    "A parting note: These tools are not _always_ the best choice, or even applicable. For example, the Simpson's rule was the favored method of Naval Architects because it gives good results when sampling the hull off of a lines plan drawing at regular intervals. All of our analysis depends on an analytic Greens function, $G$, making high precision methods such as Gaussian quadratures and AutoDiff hard to beat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
